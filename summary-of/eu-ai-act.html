<!doctype html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="description" content="Summary of the European AI Act for web development teams: compliance and preparation."><link rel="stylesheet" href="/website/index.18f339c8.css"><title>Summary of the European AI Act</title></head><body class="body"> <header> <h1>Summary of the European AI Act</h1> </header> <main class="main"> <article> <h2>Overview</h2> <p> This article is intended for teams using or planning to use AI on their websites and apps. It provides an overview of risk, requirements, governance, and how to achieve compliance. </p> <p> The majority of obligations fall on providers or developers of high-risk AI systems but developers of apps, including those using AI for educational purposes, may be involved in work that is classed as minimal risk, and is therefore subject to (lighter) obligations. </p> <p> The following summary of risk and requirements is taken from the <a href="https://www.europarl.europa.eu/topics/en/article/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence">summary</a> provided by the European Parliament. </p> <p> The new rules establish obligations for providers and users depending on the level of risk from artificial intelligence. </p> <h3>Unacceptable risk</h3> <p>Don't do these things:</p> <ul> <li> Cognitive behavioural manipulation of people or specific vulnerable groups </li> <li>Social scoring</li> <li>Biometric identification and categorisation of people</li> <li> Real-time and remote biometric identification systems, such as facial recognition </li> </ul> <p> Article 5 of the act covers <a href="https://artificialintelligenceact.eu/article/5/">prohibited AI practices</a> in detail. </p> <h3>High risk</h3> <p> <em>Category 1</em> is concerned with products such as lifts, medicines and planes. </p> <p> Some areas of <em>Category 2</em> are specialised but others may be of relevance to developers of certain kinds of software. </p> <p> If you are involved in any of the following, find out what your obligations are: </p> <ul> <li>Management and operation of critical infrastructure</li> <li>Education and vocational training</li> <li>Employment, worker management and access to self-employment</li> <li> Access to and enjoyment of essential private services and public services and benefits </li> <li>Law enforcement</li> <li>Migration, asylum and border control management</li> <li> Assistance in legal interpretation and application of the law. </li> </ul> <h2>Transparency requirements</h2> <h3>Use of Generative AI</h3> <p> While not classified as high-risk, the use of Generative AI, like ChatGPT, will have to comply with transparency requirements and EU copyright law. </p> <p>You can comply by:</p> <ul> <li>Disclosing that the content was generated by AI</li> <li> Designing the model to prevent it from generating illegal content </li> <li>Publishing summaries of copyrighted data used for training</li> </ul> <p>For example:</p> <blockquote> <p> High-impact general-purpose AI models that might pose systemic risk, such as the more advanced AI model GPT-4, would have to undergo thorough evaluations and any serious incidents would have to be reported to the European Commission. </p> <p> Content that is either generated or modified with the help of AI - images, audio or video files (for example deepfakes) - need to be clearly labelled as AI generated so that users are aware when they come across such content. </p> <cite><a href="https://www.europarl.europa.eu/topics/en/article/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence">EU AI Act: first regulation on artificial intelligence</a></cite> </blockquote> <h3>How should AI generated content be labelled?</h3> <p> <a href="https://osf.io/preprints/psyarxiv/v4mfz">What label should be applied to content produced by generative AI?</a> by Epstein et al., considered how nine labels are perceived by people in the US, Mexico, Brazil, India, and China. </p> <p>The paper is worth a read, here is a flavour of it:</p> <blockquote> <p> <strong>AI generated</strong>, <strong>Generated with an AI tool</strong>, and <strong>AI Manipulated</strong> are the terms that participants most consistently associated with content that was generated using AI. </p> <p> However, if the goal is to identify content that is misleading (e.g., our second research question), these terms perform quite poorly. Instead, <strong>Deepfake</strong> and <strong>Manipulated</strong> are the terms most consistently associated with content that is potentially misleading. </p> <p>[<em>Ed. the labels have been highlighted for emphasis.</em>]</p> </blockquote> <h2>Governance</h2> <p>How will the AI Act be implemented?</p> <blockquote> <p> The <a href="https://digital-strategy.ec.europa.eu/en/policies/ai-office">AI Office</a> will be established, sitting within the Commission, to monitor the effective implementation and compliance of <abbr title="General purpose AI">GPAI</abbr> model providers. </p> </blockquote> <h2>Next steps</h2> <p> For the majority of app developers, the AI Act will not apply until thirty-six months from the date of the entry into force of the AI Act: <a href="https://artificialintelligenceact.eu/responsibilities-of-european-commission-ai-office/">2 August 2027</a>. </p> <p> Although that may seem a long way off, compliance may not be trivial; we advise you to begin assessing your responsibilities. </p> <p> In an appendix to the summary, there are a number of use cases you may find useful. </p> <p>For example:</p> <blockquote> <p> <strong>Education and vocational training</strong>: AI systems determining access, admission or assignment to educational and vocational training institutions at all levels. Evaluating learning outcomes, including those used to steer the student’s learning process. </p> <p> Assessing the appropriate level of education for an individual. Monitoring and detecting prohibited student behaviour during tests. </p> <p>[<em>Ed. the use case has been highlighted for emphasis.</em>]</p> </blockquote> <aside> <p> For most apps, the date when the EU AI Act comes into force is <strong>2 August 2027</strong>. </p> <p> Check your obligations under the act using the <a href="https://artificialintelligenceact.eu/assessment/eu-ai-act-compliance-checker/">EU AI Act Compliance Checker</a>. </p> </aside> <hr> <p><em>This article was published on 18th October 2024.</em></p> <hr> <h2>Links to external references</h2> <dl> <dt> <a href="https://www.europarl.europa.eu/topics/en/article/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence">EU AI Act: first regulation on artificial intelligence</a> </dt> <dd> <p> The use of artificial intelligence in the EU will be regulated by the AI Act, the world’s first comprehensive AI law. </p> <p><em>Article published by the European Parliament.</em></p> </dd> <dt> <a href="https://artificialintelligenceact.eu/high-level-summary/">High-level summary of the AI Act </a> </dt> <dd> <p> <em>Updated on 30 May 2024 in accordance with the Corrigendum version of the AI Act.</em> </p> <p> In this article we provide you with a high-level summary of the AI Act, selecting the parts which are most likely to be relevant to you regardless of who you are. We provide links to the original document where relevant so that you can always reference the Act text. </p> <p><em>The EU Artificial Intelligence Act.</em></p> </dd> <dt> <a href="https://artificialintelligenceact.eu/assessment/eu-ai-act-compliance-checker/">EU AI Act Compliance Checker</a> </dt> <dd> <p> The EU AI Act introduces new obligations to entities located within the EU and elsewhere. Use our interactive tool to determine whether or not your AI system will be subject to these. </p> <p><em>The EU Artificial Intelligence Act.</em></p> </dd> </dl> </article> </main> <footer> <nav aria-label="Primary"> <a class="local" href="/website/sitemap.html">Human-readable sitemap</a> </nav> </footer> </body></html>