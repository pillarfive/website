<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta
      name="description"
      content="How-to guide to building a Chrome extension that tracks CO2 emissions from web pages. Learn how to handle request types, use fetch API, and optimize compression rates."
    />
    <link rel="stylesheet" href="/src/styles/common.css" />
    <title>
      How to Build a Chrome Extension to Track Web Page CO2 Emissions
    </title>
  </head>
  <body class="body">
    <header>
      <h1>Build a Chrome Extension to Track Web Page CO2 Emissions</h1>
    </header>
    <main class="main">
      <p>
        Pages have weight, some more than others, and
        <a href="https://httparchive.org/reports/page-weight#bytesTotal"
          >the median size is growing</a
        >.
      </p>
      <p>
        Measuring emissions associated with page weight is a relatively new
        practice and given the number of factors to be controlled for, any
        values should be regarded as estimates.
      </p>
      <p>
        But estimates are sufficient to compare pages across sites and for
        development teams to use them to compare versions of their pages over
        time.
      </p>
      <p>
        Keeping an eye on emissions also means being aware of the individual
        requests that make up a page. This number is in the hundreds for sites
        that pull in data from many sources and employ third party tracking and
        advertising.
      </p>
      <p>
        The emissions tracker lets visitors view requests and emissions in real
        time, as the page loads.
      </p>
      <h2>Architecture</h2>
      <p>
        The extension relies on the service worker to monitor and process
        requests and the side panel to display them.
      </p>
      <p>
        The
        <a
          href="https://developer.chrome.com/docs/extensions/develop/concepts/service-workers"
          ><strong>service worker</strong></a
        >
        has access to indexedDB (the browserâ€™s built-in database) but not the
        DOM.
      </p>
      <p>
        This
        <a
          href="https://developer.chrome.com/docs/extensions/reference/api/sidePanel"
          ><strong>side panel</strong></a
        >
        has access to the Window object and Chrome's APIs.
      </p>
      <p>
        When a visitor first opens the extension by clicking on the icon, they
        are asked to refresh the page to begin tracking emissions. Thereafter
        one of three scenarios takes place.
      </p>
      <ul>
        <li>
          <strong>Scenarios</strong>: The extension keeps tracking emissions as
          new requests come in but when the page is reloaded or the visitor
          navigates to a new site, we:
          <ul>
            <li>Clear the indexedDB store</li>
            <li>Reset the display in the side panel</li>
          </ul>
          When the visitor clicks on a different, already open, tab, we:
          <ul>
            <li>Clear the indexedDB store</li>
            <li>Close the side panel</li>
            <li>Disable request listeners</li>
          </ul>
          We disable the listeners because service workers
          <a
            href="https://developer.chrome.com/docs/extensions/develop/concepts/service-workers"
            >generally run</a
          >
          until the browser is closed or the extension is removed.
        </li>
        <li>
          <strong>Initial state</strong>: Every time the visitor opens the side
          panel by clicking on the extension icon, we show the message "Please
          reload the page to capture website emissions". This is necessary
          because we don't have access to 'historical' requests i.e. requests
          made before the extension service worker was initialised.
        </li>
      </ul>
      <h2>Service worker</h2>
      <p>
        The extension service worker is responsible for intercepting requests,
        storing them, processing them (sorting, etc.) and messaging the side
        panel.
      </p>
      <ul>
        <li>
          <code><strong>fetch(url)</strong></code
          >: The service worker intercepts requests using the fetch API.
        </li>
        <li>
          <code><strong>response.clone()</strong></code
          >: Clone the response because a Response object can only be consumed
          once. Cloning lets you keep the original response intact while
          processing a copy.
        </li>
        <li>
          <code><strong>indexedDB</strong></code
          >: Save request information to indexedDB so that the data can be read
          back and processed e.g. sorted and grouped.
        </li>
        <li>
          <code><strong>chrome.runtime.sendMessage</strong></code
          >: The service worker messages the side panel after every request with
          a fresh data.
        </li>
      </ul>
      <h2>Side panel</h2>
      <ul>
        <li>
          <code><strong>chrome.runtime.onMessage.addListener</strong></code
          >: The side panel listens for messages from the service worker. It is
          responsible for displaying a summary (bytes, request count, associated
          emissions and whether the site is green hosted), request details
          grouped by <code>type</code>, and listing failed requests.
        </li>
      </ul>
      <h2>Request size (bytes transferred)</h2>
      <p>
        Unless the server responsible for serving a cross-origin request has set
        <a href="Access-Control-Expose-Headers"
          ><code>Access-Control-Expose-Headers</code></a
        >
        the content length is 0. In order to find bytes transferred, we need to
        look at the content length and then, if compression has been used, apply
        it.
      </p>
      <ul>
        <li>
          <strong>Performance API</strong>: We cannot use the Performance API
          because
          <a
            href="https://developer.mozilla.org/en-US/docs/Web/API/PerformanceResourceTiming"
            >transferSize is 0</a
          >
          for cross-origin requests where the appropriate
          <abbr title="Cross-Origin Resource Sharing">CORS</abbr> headers have
          not been set e.g.
          <code>Timing-Allow-Origin: https://developer.mozilla.org</code>
        </li>
        <li>
          <code><strong>fetch(url)</strong></code
          >: Where available, we use content-length, and, if not, byte length.
          Since this value is the original size of the resource, we have to
          compress it.
        </li>
        <li>
          <strong>Compression strategy</strong>: Given the size in bytes of the
          original resource, resource type (CSS, JavaScript, etc.) and the
          encoding type (brotli, gzip, etc.) we estimate the size of the
          compressed, transferred, size of the resource. Compression rates for
          resources vary between sites due to server behaviour, so we select
          compression levels, and rates, that are representative. For some
          sites, the resulting byte value may be high or low.
          <code>
            const compressionRate = getCompressionStrategy( requestType,
            encoding, uncompressedBytes ).rate
          </code>
        </li>
        <li>
          <strong>Practice</strong>: Due to uncertainty around compression rates
          and emissions calculations, the tracker is most useful for comparing
          values between different versions of the same site.
        </li>
      </ul>
      <h2>How emissions are calculated</h2>
      <h3>The Green Web Foundation (TGWF)</h3>
      <p>
        Once we have a byte count, we can calculate its associated emissions.
        <abbr title="The Green Web Foundation">TGWF</abbr> provides a useful set
        of methods and a clear
        <a href="https://sustainablewebdesign.org/estimating-digital-emissions/"
          >methodology</a
        >. We recommend using <a href="https://ecograder.com/">Ecograder</a> for
        a comparative analysis.
      </p>
      <ul>
        <li>
          In order to use the
          <a href="https://developers.thegreenwebfoundation.org/co2js/methods/"
            >methods</a
          >
          provided by the <abbr title="The Green Web Foundation">TGWF</abbr>, I
          forked the
          <a href="https://github.com/thegreenwebfoundation/co2.js/">repo</a>,
          and copied the build files generated by running
          <code>npm run build</code>. We imported <code>hosting</code> and
          <code>co2</code> into the project.
        </li>
        <li>
          A call to <code>hosting.check(domain)</code> returns a boolean value
          for <code>greenHosting</code>, displayed as "green hosted".
        </li>
        <li>
          A call to <code>CO2.perByte(bytes, greenHosting)</code> returns a
          value for emissions in g (grams) of CO2.
        </li>
      </ul>
      <h2>Features</h2>
      <ul>
        <li>
          <strong>Comparison with previous</strong>: If the visitor previously
          saved data (in the side panel's Local storage), current data are
          compared against them. An arrow up (red) indicates a rise (in
          emissions, requests or bytes), and an arrow down (green) a fall.
        </li>
        <li>
          <strong>Exporting data</strong>: Clicking on the "Export data" button
          results in the option to save the summary and requests grouped by type
          to a local file.
        </li>
        <li>
          <strong>Overriding compression rates</strong>: There is a pending
          feature request to override the default rates with custom rates better
          tailored to the visitor's needs (the compression rates used on a
          site). Since compression strategy is an object literal, overrides
          could be exported in JSON format.
        </li>
      </ul>
      <h2>Purpose</h2>
      <p>
        The cost of our actions is of general interest and the emissions tracker
        provides a simple way to see the impact of a web page.
      </p>
      <p>
        The emissions tracker is also an inducement to development teams to
        spend more time looking at how their web sites and apps behave in the
        browser where they are used and seen by others.
      </p>
      <p>
        At People and Code we spend a lot of time in the browser and build tools
        to help us there.
      </p>
      <aside aria-labelledby="authors-heading">
        <h3 id="authors-heading">Authors</h3>
        <p>This document was created with the help of ChatGPT and Claude.</p>
      </aside>
    </main>
    <footer>
      <nav aria-label="Primary">
        <a href="/src/sitemap.html">Link to human-readable sitemap in nav</a>
      </nav>
    </footer>
  </body>
</html>
